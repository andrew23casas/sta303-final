---
title: "Report title"
author: "Report prepared for MINGAR by [consulting company name]"
date: '2022-04-07'
output:
  pdf_document:
    template: report.tex
    toc: yes
    toc_depth: 2
  html_document:
    toc: yes
    toc_depth: '2'
    df_print: paged
lang: en
subtitle: Subtitle that indicates findings
titlepage: yes
titlepage-color: 6C3082
titlepage-text-color: FFFFFF
titlepage-rule-color: FFFFFF
titlepage-rule-height: 2
---

```{r, message = FALSE, echo=FALSE}
library(tidyverse)
library(lme4)
library(ggplot2)
library(rvest)
library(polite)
library(lmtest)
library(readr)
library(cancensus)
library(geojsonsf)
library(ggpubr)
library(haven)
# this should suppress all code and messages
```

# General comments (you can delete this section)

_Before making any changes, knit this Rmd to PDF and change the name of the PDf to something like 'original-instructions.pdf', or whatever you like (it is just for your reference).. Then you can delete this section and if you want to check what it said, just open the other PDF. You don't HAVE to use this particular template, but you DO need to write you report in RMarkdown and include a cover page._

_The cover page must be a single stand alone page and have:_

*	_A title and subtitle (that indicate your findings)_
* _"Report prepared for MINGAR by" your company name_
*	_Date (assessment submission date is fine)_

_You can change the colour of this cover to any colour you would like by replacing 6C3082 in the YAML above (`titlepage-color:`) to another hex code. You could use this tool to help you:_ https://htmlcolorcodes.com/color-picker/

_Note: There should NOT be a table of contents on the cover page. It should look like a cover._

\newpage
# Executive summary

_Guidelines for the executive summary:_

* _No more than two pages_
* _Language is appropriate for a non-technical audience_
* _Bullet points are used where appropriate_
*	_A small number of key visualizations and/or tables are included_
*	_All research questions are addressed_


_The [module 4 writing prompt](https://sta303-bolton.github.io/sta303-w22-courseguide/knowledge-basket-writing-and-peer-feedback.html#module-4-writing-task) provides some tips and information about writing executive summaries._


\newpage
# Technical report
_This part of the report is much more comprehensive than the executive summary. The audience is statistics/data-minded people, but you should NOT include code or unformatted R output here._


## Introduction

_Provide a brief introduction to your report and outline what the report will cover. This section is valuable for setting scope and expectations. _

### Research questions
_Use bullet points to to describe the research questions you are going to address. Write in full sentences._
- How are buyers of the newer and more affordable models different than our customers who purchased traditional products?
- What are the main demographic factors of customers that help predict which line of product they will purchase?


## Informative title for section addressing a research question

_For each research question, you will want to briefly describe any data manipulation, show some exploratory plots/summary tables, report on any methods you use (i.e. models you fit) and the conclusions you draw from these_


How we gathered the data and cleaned
how we got the conversion file and census api
why we chose age and income into categories
why we chose the increments we did
how and why we chose to visualize the data
why we chose glm
how-why we chose our predictors
why we chose LRT





```{r include=FALSE, echo=TRUE}

#clean the conversion file
post_file <- post_file %>% 
  select(CSDuid, PC, Comm_Name)

#merge CSDuid
inc_post_merge <- merge(post_file, median_income, by = "CSDuid")

#change column name to merge to customer dataset
inc_post_merge <- inc_post_merge %>% 
  select(-'CSDuid') %>% 
  unique() %>% 
  rename('postcode'='PC')

#merge to customer dataset
post_cust_merge <- merge(customer, inc_post_merge, by= 'postcode') %>% 
  select(-'Population',-'emoji_modifier') 

#create main dataset we will use
income_dev_merge <- merge(post_cust_merge, cust_dev, by="cust_id")

main_data <- merge(income_dev_merge, device_data, by="dev_id") %>% 
  distinct(cust_id, .keep_all = T) %>% 
  select(-'device_name') %>% 
  mutate(prod_cat = case_when(
    endsWith(line, "L") ~ "Traditional",
    endsWith(line,"n") ~ "Traditional",
    endsWith(line,"e")~"Affordable")) 

#make data categorical to visualize
main_data$dob = round(as.numeric(difftime(Sys.Date(),main_data$dob, units = "weeks"))/52.25)

main_data <- main_data %>% 
  mutate(age_group = case_when(
    dob <= 25 ~ "15-25",
    dob <= 35 ~ "26-35",
    dob <= 45 ~ "36-45",
    dob <= 55 ~ "46-55",
    dob > 55 ~ "55+"
  )) %>% 
  mutate(generation = case_when(
    dob <= 25 ~ "Gen-Z",
    dob <= 41 ~ "Millenial",
    dob <= 57 ~ "Gen-X",
    dob > 57 ~ "Boomer"
  )) %>%
  mutate(median_income = case_when(
    hhld_median_inc <= 60000 ~ "< $60000",
    hhld_median_inc <= 70000 ~ "$60000 - $70000",
    hhld_median_inc <= 80000 ~ "$70000 - $80000",
    hhld_median_inc <= 90000 ~ "$80000 - $90000",
    hhld_median_inc > 90000 ~ "$90000+"
  )) %>% 
  select(-c(cust_id, dev_id, postcode, released)) %>% 
  rename(age = dob) %>% 
  drop_na()
#generation is better than age groups and tax brackets were not worth doing 

#creating bar plot
sex_graph <- ggplot(data=main_data, aes(x = sex, fill=prod_cat)) +
  geom_bar(position = 'dodge')+
  xlab(label = "Sex")+
  ylab(label = "Number of Customers")+
  ggtitle("Customer Sex Distribution")+
  guides(fill=guide_legend(title=NULL))+
  scale_x_discrete(guide = guide_axis(angle = 50))

gen_graph <- ggplot(data=main_data, aes(x = generation, fill=prod_cat)) +
  geom_bar(position = 'dodge')+
  xlab(label = "Generation")+
  ylab(label = "Number of Customers")+
  ggtitle("Customer Generation Distribution")+
  guides(fill=guide_legend(title=NULL))+
  scale_x_discrete(guide = guide_axis(angle = 50), limits = c("Gen-Z", "Millenial", "Gen-X", "Boomer"))

income_graph <- ggplot(data=main_data, aes(x = median_income, fill=prod_cat)) +
  geom_bar(position = 'dodge')+
  xlab(label = "Median Income")+
  ylab(label = "Number of Customers")+
  ggtitle("Customer Income Distribution")+
  guides(fill=guide_legend(title=NULL))+
  scale_x_discrete(guide = guide_axis(angle = 50), limits=c("< $60000", "$60000 - $70000",
                                                            "$70000 - $80000", "$80000 - $90000", "$90000+" ))
pronoun_graph <- ggplot(data=main_data, aes(x = pronouns, fill=prod_cat)) +
  geom_bar(position = 'dodge')+
  xlab(label = "Pronouns")+
  ylab(label = "Number of Customers")+
  ggtitle("Customer Pronoun Distribution")+
  guides(fill=guide_legend(title=NULL))+
  scale_x_discrete(guide = guide_axis(angle = 50))

figure <- ggarrange(sex_graph, gen_graph, income_graph, pronoun_graph,
                    ncol = 2, nrow = 2)

#creating dataset for models
model_data <- main_data %>% 
    mutate(binary_prod_cat = case_when(
    endsWith(prod_cat, "l") ~ 0,
    endsWith(prod_cat,"e") ~ 1))


cat_complex_mod <- glm(binary_prod_cat ~ sex  + age_group + pronouns +
                     median_income,family=binomial(), data = model_data)

cat_mod1 <- glm(binary_prod_cat ~  sex + age_group + 
                     median_income,family=binomial(), data = model_data)

cat_mod2 <- glm(binary_prod_cat ~  age_group +
                     median_income,family=binomial(), data = model_data)

cat_mod3 <- glm(binary_prod_cat ~ median_income,family=binomial(), 
                data = model_data)

cat_mod4 <- glm(binary_prod_cat ~ age_group,family=binomial(), 
                data = model_data)

cat_gen_mod1 <- glm(binary_prod_cat ~ generation + Comm_Name + median_income 
                    ,family=binomial(), data = model_data)

cat_gen_mod2 <- glm(binary_prod_cat ~ generation + median_income
                    , family=binomial(), data = model_data)

lrtest(cat_gen_mod1,cat_gen_mod2)


dis_complex_mod <- glm(binary_prod_cat ~ sex  + age + pronouns +
                     hhld_median_inc,family=binomial(), data = model_data)

dis_mod1 <- glm(binary_prod_cat ~  sex + age + 
                     hhld_median_inc,family=binomial(), data = model_data)

dis_mod2 <- glm(binary_prod_cat ~  age + 
                     hhld_median_inc,family=binomial(), data = model_data)

dis_mod3 <- glm(binary_prod_cat ~ hhld_median_inc,family=binomial(), 
                data = model_data)

dis_mod4 <- glm(binary_prod_cat ~ age,family=binomial(), 
                data = model_data)

summary(cat_gen_mod2)


```

## Informative title for section addressing a research question

### Methods


## Discussion

_In this section you will summarize your findings across all the research questions and discuss the strengths and limitations of your work. It doesn't have to be long, but keep in mind that often people will just skim the intro and the discussion of a document like this, so make sure it is useful as a semi-standalone section (doesn't have to be completely standalone like the executive summary)._

### Strengths and limitations


Limitations and strengths: Some of the limitations of our model arise from the data. For example, the Canadian census data for median household income is not an exact measure of individual income. To alleviate this, we implemented income ranges to capture ‘small’ deviations from the median. Furthermore, the glm framework assumes independences between predictors but we know that in the real world, age and income are correlated. The given dataset includes ages as young as 17 and as old as 92. In general, we know that between the ages of 17-24, most people are in school and either unemployed or have entry level jobs. Similarly, people older aged 65 or older are typically retired. Consequently, this means that people aged 25-64 will have a higher disposable income relative to the other age groups. We can also note that a factor that we cannot account for is the environment each customer is brought up in. For example, someone who is raised by parents who work in the tech industry may be more inclined to purchase tech products. 
Our analysis regarding the performance of Mingar products on users with different skin tones is dependent on the skin tone of the emojis that the users have picked for themselves, it may not necessarily reflect their skin tone as the choices are limited and subjective. This may be a limitation as it is not possible for us to process data related to the users’ actual skin tones.
Moreover, since we have limited number of observations, we opted to use the duration data since it might be significantly different varying from user to user. However, duration may have alternate consequences independent from the skin tone of the users which we may not be able to observe with the given data (such as the product wearing out). Nevertheless, in order to make things simpler, we carried out the analysis depending on flags and duration.
In relation to the aforementioned limitation, we should also note that an already problematic product used by one of the users could result in an unusual number of flags irrespective of the skin tone of the user which may impair our results.


\newpage
# Consultant information
## Consultant profiles

*Complete this section with a brief bio for each member of your group. If you are completing the project individually, you only need to complete one for yourself. In that case, change the title of this section to 'Consultant profile' instead. Examples below. This section is only marked for completeness, clarity and professionalism, not 'truth' so you can write it as if we're a few years in the future. Put your current degree in as completed and/or add your first choice grad school program, whatever you like. What skills related skills would you most like to highlight? What job title do you want?*

**Ahmad Noori**. Ahmad is a junior consultant with StatsCorp. He specializes in data visualization. Ahmad  earned his Bachelor of Science, consisting of a double major in Statistics and Actuarial Science, from the University of Toronto in 2020.

**Andrew Casas**. Andrew is a Senior consultant with StatsCorp. He specializes in data wrangling. Andrew  graduated from the University of Toronto in 2021 with a Bachelor of Science, consisting of a double major in Statistics and Mathematics.

**Can Coksiler**. Can is a junior consultant with StatsCorp. He is proficient in Python, R, Javascript, and Java; and
specializes in statistical analysis using R. Can is working on completing a Bachelor of Science with a
double major in Statistics and Cognitive Science at the University of Toronto

**Zeynep Hazal Karadeniz**. Zeynep has graduated from the University of Toronto with a double major in Economics and Statistics (with focus on data analysis). She has been a part of our team for 3 years, focusing on our clients’ needs mainly in the marketing field. She is highly experienced in sector-specific data analytics and data visualization.


## Code of ethical conduct

The study was conducted with utmost care and attention during both the data collection and analysis phases and sensitive personal data involved were processed anonymously and in compliance with relevant data protection regulations. StatsCorp undertakes that it has not acted in violation of such regulations and it abides every and all modern ethical standard in relation to the services provided to Mingar under the contract.

_This section should be fairly short, no more than half a page. Assume a general audience, much like your executive summary._

* _Make at least three relevant statements about your company's approach to ethical statistical consulting. These should be appropriately in line with professional conduct advice like the (Statistical Society of Canada Code of Conduct)[https://ssc.ca/sites/default/files/data/Members/public/Accreditation/ethics_e.pdf] or the (Ethical Guidelines for Statistical Practice from the American Statistical Society)[https://www.amstat.org/ASA/Your-Career/Ethical-Guidelines-for-Statistical-Practice.aspx]. For example, "the customer is always right" ISN'T the type of thing an ethical statistical consultant would include._
*	_Be very careful not to just copy and paste from these other documents! Put things in your own words._


\newpage
# References

_You don't need to cite course materials, but consider all the the places you got data from, as well as the packages used and R itself. These are all things you should consider citing. Likewise, you might use some external resources on the emoji skin tones/Fitzpatrick scale, etc._

\newpage
# Appendix

_These appendices should outline in more detail the steps taken to access the following datasets. They should NOT include code, but should briefly describe the steps and important considerations. I.e., show that you understand what needs to be considered when web scraping, protecting licensed data, etc._

## Web scraping industry data on fitness tracker devices

## Accessing Census data on median household income

## Accessing postcode conversion files


__Final advice: KNIT EARLY AND OFTEN!__
